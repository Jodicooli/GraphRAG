{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# GraphRAG API Demo\n",
    "\n",
    "This notebook is written as an advanced tutorial/demonstration on how to use the GraphRAG solution accelerator API. It builds on top of the concepts covered in the `1-Quickstart` notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## Existing APIs\n",
    "\n",
    "| HTTP Method | Endpoint         |\n",
    "|-------------|------------------|\n",
    "| GET         | /data\n",
    "| POST        | /data\n",
    "| DELETE      | /data/{storage_name}\n",
    "| GET         | /index\n",
    "| POST        | /index\n",
    "| DELETE      | /index/{index_name}\n",
    "| GET         | /index/status/{index_name}\n",
    "| POST        | /query/global\n",
    "| POST        | /query/streaming/global\n",
    "| POST        | /query/local\n",
    "| POST        | /query/streaming/local\n",
    "| GET         | /index/config/prompts\n",
    "| GET         | /source/report/{index_name}/{report_id}\n",
    "| GET         | /source/text/{index_name}/{text_unit_id}\n",
    "| GET         | /source/entity/{index_name}/{entity_id}\n",
    "| GET         | /source/claim/{index_name}/{claim_id}\n",
    "| GET         | /source/relationship/{index_name}/{relationship_id}\n",
    "| GET         | /graph/graphml/{index_name}\n",
    "| GET         | /graph/stats/{index_name}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Install 3rd party packages that are not part of the Python Standard Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install devtools pandas python-magic requests tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import json\n",
    "import sys\n",
    "import time\n",
    "from pathlib import Path\n",
    "\n",
    "import magic\n",
    "import pandas as pd\n",
    "import requests\n",
    "from devtools import pprint\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5",
   "metadata": {},
   "source": [
    "## (REQUIRED) User Configuration\n",
    "Set the API subscription key, API base endpoint, and some file directory names that will be referenced later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### API subscription key\n",
    "\n",
    "APIM supports multiple forms of authentication and access control (e.g. managed identity). For this notebook demonstration, we will use a **[subscription key](https://learn.microsoft.com/en-us/azure/api-management/api-management-subscriptions)**. To locate this key, visit the Azure Portal. The subscription key can be found under `<my_resource_group> --> <API Management service> --> <APIs> --> <Subscriptions> --> <Built-in all-access subscription> Primary Key`. For multiple API users, individual subscription keys can be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "ocp_apim_subscription_key = getpass.getpass(\n",
    "    \"Enter the subscription key to the GraphRag APIM:\"\n",
    ")\n",
    "\n",
    "\"\"\"\n",
    "\"Ocp-Apim-Subscription-Key\": \n",
    "    This is a custom HTTP header used by Azure API Management service (APIM) to \n",
    "    authenticate API requests. The value for this key should be set to the subscription \n",
    "    key provided by the Azure APIM instance in your GraphRAG resource group.\n",
    "\"\"\"\n",
    "headers = {\"Ocp-Apim-Subscription-Key\": ocp_apim_subscription_key}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "#### Setup directories and API endpoint\n",
    "\n",
    "For demonstration purposes, please use the provided `get-wiki-articles.py` script to download a small set of wikipedia articles or provide your own data (graphrag requires txt files to be utf-8 encoded)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "These parameters must be defined by the notebook user:\n",
    "\n",
    "- file_directory: a local directory of text files. The file structure should be flat,\n",
    "                  with no nested directories. (i.e. file_directory/file1.txt, file_directory/file2.txt, etc.)\n",
    "- storage_name:   a unique name to identify a blob storage container in Azure where files\n",
    "                  from `file_directory` will be uploaded.\n",
    "- index_name:     a unique name to identify a single graphrag knowledge graph index.\n",
    "                  Note: Multiple indexes may be created from the same `storage_name` blob storage container.\n",
    "- endpoint:       the base/endpoint URL for the GraphRAG API (this is the Gateway URL found in the APIM resource).\n",
    "\"\"\"\n",
    "\n",
    "file_directory = \"data\"\n",
    "storage_name = \"blob\"\n",
    "index_name = \"indexAdvanced\"\n",
    "endpoint = \"https://apim-smtxoz24u6jxg.azure-api.net\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert (\n",
    "    file_directory != \"\" and storage_name != \"\" and index_name != \"\" and endpoint != \"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Helper Functions\n",
    "\n",
    "For cleanliness, we've provided helper functions below that encapsulate http requests to make API interaction with each API endpoint more intuitive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def upload_files(\n",
    "    file_directory: str,\n",
    "    container_name: str,\n",
    "    batch_size: int = 100,\n",
    "    overwrite: bool = True,\n",
    "    max_retries: int = 5,\n",
    ") -> requests.Response | list[Path]:\n",
    "    \"\"\"\n",
    "    Upload files to a blob storage container.\n",
    "\n",
    "    Args:\n",
    "    file_directory - a local directory of .txt files to upload. All files must be in utf-8 encoding.\n",
    "    container_name - a unique name for the Azure storage container.\n",
    "    batch_size - the number of files to upload in a single batch.\n",
    "    overwrite - whether or not to overwrite files if they already exist in the storage container.\n",
    "    max_retries - the maximum number of times to retry uploading a batch of files if the API is busy.\n",
    "\n",
    "    NOTE: Uploading files may sometimes fail if the blob container was recently deleted\n",
    "    (i.e. a few seconds before. The solution \"in practice\" is to sleep a few seconds and try again.\n",
    "    \"\"\"\n",
    "    url = endpoint + \"/data\"\n",
    "\n",
    "    def upload_batch(\n",
    "        files: list, container_name: str, overwrite: bool, max_retries: int\n",
    "    ) -> requests.Response:\n",
    "        for _ in range(max_retries):\n",
    "            response = requests.post(\n",
    "                url=url,\n",
    "                files=files,\n",
    "                params={\"container_name\": container_name, \"overwrite\": overwrite},\n",
    "                headers=headers,\n",
    "            )\n",
    "            # API may be busy, retry\n",
    "            if response.status_code == 500:\n",
    "                print(\"API busy. Sleeping and will try again.\")\n",
    "                time.sleep(10)\n",
    "                continue\n",
    "            return response\n",
    "        return response\n",
    "\n",
    "    batch_files = []\n",
    "    accepted_file_types = [\"text/plain\"]\n",
    "    filepaths = list(Path(file_directory).iterdir())\n",
    "    for file in tqdm(filepaths):\n",
    "        # validate that file is a file, has acceptable file type, has a .txt extension, and has utf-8 encoding\n",
    "        if (\n",
    "            not file.is_file()\n",
    "            or file.suffix != \".txt\"\n",
    "            or magic.from_file(str(file), mime=True) not in accepted_file_types\n",
    "        ):\n",
    "            print(f\"Skipping invalid file: {file}\")\n",
    "            continue\n",
    "        # open and decode file as utf-8, ignore bad characters\n",
    "        batch_files.append(\n",
    "            (\"files\", open(file=file, mode=\"r\", encoding=\"utf-8\", errors=\"ignore\"))\n",
    "        )\n",
    "        # upload batch of files\n",
    "        if len(batch_files) == batch_size:\n",
    "            response = upload_batch(batch_files, container_name, overwrite, max_retries)\n",
    "            # if response is not ok, return early\n",
    "            if not response.ok:\n",
    "                return response\n",
    "            batch_files.clear()\n",
    "    # upload remaining files\n",
    "    if len(batch_files) > 0:\n",
    "        response = upload_batch(batch_files, container_name, overwrite, max_retries)\n",
    "    return response\n",
    "\n",
    "\n",
    "def delete_files(container_name: str) -> requests.Response:\n",
    "    \"\"\"Delete an azure storage container that holds raw data.\"\"\"\n",
    "    url = endpoint + f\"/data/{container_name}\"\n",
    "    return requests.delete(url=url, headers=headers)\n",
    "\n",
    "\n",
    "def list_files() -> requests.Response:\n",
    "    \"\"\"Get a list of all azure storage containers that hold raw data.\"\"\"\n",
    "    url = endpoint + \"/data\"\n",
    "    return requests.get(url=url, headers=headers)\n",
    "\n",
    "\n",
    "def build_index(\n",
    "    storage_name: str,\n",
    "    index_name: str,\n",
    "    entity_extraction_prompt: str = None,\n",
    "    entity_summarization_prompt: str = None,\n",
    "    community_summarization_prompt: str = None,\n",
    ") -> requests.Response:\n",
    "    \"\"\"Build a graphrag index.\n",
    "    This function submits a job that builds a graphrag index (i.e. a knowledge graph) from data files located in a blob storage container.\n",
    "    \"\"\"\n",
    "    url = endpoint + \"/index\"\n",
    "    prompts = dict()\n",
    "    if entity_extraction_prompt:\n",
    "        prompts[\"entity_extraction_prompt\"] = entity_extraction_prompt\n",
    "    if entity_summarization_prompt:\n",
    "        prompts[\"summarize_descriptions_prompt\"] = entity_summarization_prompt\n",
    "    if community_summarization_prompt:\n",
    "        prompts[\"community_report_prompt\"] = community_summarization_prompt\n",
    "    return requests.post(\n",
    "        url,\n",
    "        files=prompts if len(prompts) > 0 else None,\n",
    "        params={\"index_container_name\": index_name, \"storage_container_name\": storage_name},\n",
    "        headers=headers,\n",
    "    )\n",
    "\n",
    "\n",
    "def delete_index(container_name: str) -> requests.Response:\n",
    "    \"\"\"Delete an azure storage container that holds a search index.\"\"\"\n",
    "    url = endpoint + f\"/index/{container_name}\"\n",
    "    return requests.delete(url, headers=headers)\n",
    "\n",
    "\n",
    "def list_indexes() -> list:\n",
    "    \"\"\"Get a list of all azure storage containers that hold search indexes.\"\"\"\n",
    "    url = endpoint + \"/index\"\n",
    "    response = requests.get(url, headers=headers)\n",
    "    try:\n",
    "        indexes = json.loads(response.text)\n",
    "        return indexes[\"index_name\"]\n",
    "    except json.JSONDecodeError:\n",
    "        print(response.text)\n",
    "        return response\n",
    "\n",
    "\n",
    "def index_status(container_name: str) -> requests.Response:\n",
    "    \"\"\"Get the status of a specific index.\"\"\"\n",
    "    url = endpoint + f\"/index/status/{container_name}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def global_search(\n",
    "    index_name: str | list[str], query: str, community_level: int\n",
    ") -> requests.Response:\n",
    "    \"\"\"Run a global query over the knowledge graph(s) associated with one or more indexes\"\"\"\n",
    "    url = endpoint + \"/query/global\"\n",
    "    # optional parameter: community level to query the graph at (default for global query = 1)\n",
    "    request = {\n",
    "        \"index_name\": index_name,\n",
    "        \"query\": query,\n",
    "        \"community_level\": community_level,\n",
    "    }\n",
    "    return requests.post(url, json=request, headers=headers)\n",
    "\n",
    "\n",
    "def global_search_streaming(\n",
    "    index_name: str | list[str], query: str, community_level: int\n",
    ") -> requests.Response:\n",
    "    raise NotImplementedError(\"this functionality has been temporarily removed\")\n",
    "    \"\"\"Run a global query across one or more indexes and stream back the response\"\"\"\n",
    "    url = endpoint + \"/query/streaming/global\"\n",
    "    # optional parameter: community level to query the graph at (default for global query = 1)\n",
    "    request = {\n",
    "        \"index_name\": index_name,\n",
    "        \"query\": query,\n",
    "        \"community_level\": community_level,\n",
    "    }\n",
    "    context_list = []\n",
    "    with requests.post(url, json=request, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        for chunk in r.iter_lines(chunk_size=256 * 1024, decode_unicode=True):\n",
    "            try:\n",
    "                payload = json.loads(chunk)\n",
    "                token = payload[\"token\"]\n",
    "                context = payload[\"context\"]\n",
    "                if token != \"<EOM>\":\n",
    "                    print(token, end=\"\")\n",
    "                elif (token == \"<EOM>\") and not context:\n",
    "                    print(\"\\n\")  # transition from output message to context\n",
    "                else:\n",
    "                    context_list.append(context)\n",
    "            except json.JSONDecodeError:\n",
    "                print(type(chunk), len(chunk), sys.getsizeof(chunk), chunk, end=\"\\n\")\n",
    "    display(pd.DataFrame.from_dict(context_list[0][\"reports\"]).head(10))\n",
    "\n",
    "\n",
    "def local_search(\n",
    "    index_name: str | list[str], query: str, community_level: int\n",
    ") -> requests.Response:\n",
    "    \"\"\"Run a local query over the knowledge graph(s) associated with one or more indexes\"\"\"\n",
    "    url = endpoint + \"/query/local\"\n",
    "    # optional parameter: community level to query the graph at (default for local query = 2)\n",
    "    request = {\n",
    "        \"index_name\": index_name,\n",
    "        \"query\": query,\n",
    "        \"community_level\": community_level,\n",
    "    }\n",
    "    return requests.post(url, json=request, headers=headers)\n",
    "\n",
    "\n",
    "def local_search_streaming(\n",
    "    index_name: str | list[str], query: str, community_level: int\n",
    ") -> requests.Response:\n",
    "    raise NotImplementedError(\"this functionality has been temporarily removed\")\n",
    "    \"\"\"Run a global query across one or more indexes and stream back the response\"\"\"\n",
    "    url = endpoint + \"/query/streaming/local\"\n",
    "    # optional parameter: community level to query the graph at (default for local query = 2)\n",
    "    request = {\n",
    "        \"index_name\": index_name,\n",
    "        \"query\": query,\n",
    "        \"community_level\": community_level,\n",
    "    }\n",
    "    context_list = []\n",
    "    with requests.post(url, json=request, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        for chunk in r.iter_lines(chunk_size=256 * 1024, decode_unicode=True):\n",
    "            try:\n",
    "                payload = json.loads(chunk)\n",
    "                token = payload[\"token\"]\n",
    "                context = payload[\"context\"]\n",
    "                if token != \"<EOM>\":\n",
    "                    print(token, end=\"\")\n",
    "                elif (token == \"<EOM>\") and not context:\n",
    "                    print(\"\\n\")  # transition from output message to context\n",
    "                else:\n",
    "                    context_list.append(context)\n",
    "            except json.JSONDecodeError:\n",
    "                print(type(chunk), len(chunk), sys.getsizeof(chunk), chunk, end=\"\\n\")\n",
    "    for key in context_list[0].keys():\n",
    "        display(pd.DataFrame.from_dict(context_list[0][key]).head(10))\n",
    "\n",
    "\n",
    "def save_graphml_file(index_name: str, graphml_file_name: str) -> None:\n",
    "    \"\"\"Retrieve and save a graphml file that represents the knowledge graph.\n",
    "    The file is downloaded in chunks and saved to the local file system.\n",
    "    \"\"\"\n",
    "    url = endpoint + f\"/graph/graphml/{index_name}\"\n",
    "    if Path(graphml_file_name).suffix != \".graphml\":\n",
    "        raise UserWarning(f\"{graphml_file_name} must have a .graphml file extension\")\n",
    "    with requests.get(url, headers=headers, stream=True) as r:\n",
    "        r.raise_for_status()\n",
    "        with open(graphml_file_name, \"wb\") as f:\n",
    "            for chunk in r.iter_content(chunk_size=1024):\n",
    "                f.write(chunk)\n",
    "\n",
    "\n",
    "def get_report(index_name: str, report_id: str) -> requests.Response:\n",
    "    \"\"\"Retrieve a report generated by GraphRAG for a specific index.\"\"\"\n",
    "    url = endpoint + f\"/source/report/{index_name}/{report_id}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def get_entity(index_name: str, entity_id: str) -> requests.Response:\n",
    "    \"\"\"Retrieve an entity generated by GraphRAG for a specific index.\"\"\"\n",
    "    url = endpoint + f\"/source/entity/{index_name}/{entity_id}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def get_relationship(index_name: str, relationship_id: str) -> requests.Response:\n",
    "    \"\"\"Retrieve a relationship generated by GraphRAG for a specific index.\"\"\"\n",
    "    url = endpoint + f\"/source/relationship/{index_name}/{relationship_id}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def get_claim(index_name: str, claim_id: str) -> requests.Response:\n",
    "    \"\"\"Retrieve a claim/covariate generated by GraphRAG for a specific index.\"\"\"\n",
    "    url = endpoint + f\"/source/claim/{index_name}/{claim_id}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def get_text_unit(index_name: str, text_unit_id: str) -> requests.Response:\n",
    "    \"\"\"Retrieve a text unit generated by GraphRAG for a specific index.\"\"\"\n",
    "    url = endpoint + f\"/source/text/{index_name}/{text_unit_id}\"\n",
    "    return requests.get(url, headers=headers)\n",
    "\n",
    "\n",
    "def parse_query_response(\n",
    "    response: requests.Response, return_context_data: bool = False\n",
    ") -> requests.Response | dict[list[dict]]:\n",
    "    \"\"\"\n",
    "    Prints response['result'] value and optionally\n",
    "    returns associated context data.\n",
    "    \"\"\"\n",
    "    if response.ok:\n",
    "        print(json.loads(response.text)[\"result\"])\n",
    "        if return_context_data:\n",
    "            return json.loads(response.text)[\"context_data\"]\n",
    "        return response\n",
    "    else:\n",
    "        print(response.reason)\n",
    "        print(response.content)\n",
    "        return response\n",
    "\n",
    "\n",
    "def generate_prompts(container_name: str, limit: int = 1) -> None:\n",
    "    \"\"\"Generate graphrag prompts using data provided in a specific storage container.\"\"\"\n",
    "    url = endpoint + \"/index/config/prompts\"\n",
    "    params = {\"container_name\": container_name, \"limit\": limit}\n",
    "    return requests.get(url, params=params, headers=headers)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "## Upload files\n",
    "\n",
    "Use the API to upload a collection of local files. The API will create a new storage blob container to host these files in. For a set of large files, consider reducing the batch upload size in order to not overwhelm the API endpoint and prevent out-of-memory problems."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 87.07it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n"
     ]
    }
   ],
   "source": [
    "response = upload_files(\n",
    "    file_directory=file_directory,\n",
    "    container_name=storage_name,\n",
    "    batch_size=100,\n",
    "    overwrite=True,\n",
    ")\n",
    "if not response.ok:\n",
    "    print(response.text)\n",
    "else:\n",
    "    print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "#### To list all existing data storage containers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "16",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{\n",
      "    'storage_name': [\n",
      "        'datatest',\n",
      "        'blob',\n",
      "    ],\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = list_files()\n",
    "print(response)\n",
    "if response.ok:\n",
    "    pprint(response.json())\n",
    "else:\n",
    "    pprint(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17",
   "metadata": {},
   "source": [
    "#### To remove files from the GraphRAG service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment this cell to delete data container\n",
    "# response = delete_files(storage_name)\n",
    "# print(response)\n",
    "# pprint(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19",
   "metadata": {},
   "source": [
    "## Auto-Template Generation (Optional)\n",
    "\n",
    "GraphRAG constructs a knowledge graph from data based on the ability to identify entities and the relationships between them. To improve the quality of the knowledge graph constructed by GraphRAG over private data, we provide a feature called \"Automatic Templating\". This capability takes user-provided data samples and generates custom-tailored prompts based on characteristics of that data. These custom prompts contain few-shot examples of entities and relationships, which can then be used to build a graphrag index."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b523b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "auto_template_response = generate_prompts(container_name=storage_name, limit=1)\n",
    "if auto_template_response.ok:\n",
    "    prompts = auto_template_response.json()\n",
    "else:\n",
    "    print(auto_template_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "After running the previous cell, a new local directory (`prompts`) will be created. Please look at the prompts (`prompts/entity_extraction.txt`, `prompts/community_report.txt`, and `prompts/summarize_descriptions.txt`) that were generated from the user-provided data. Users are encouraged to spend some time and inspect/modify these prompts, taking into account characteristics of their data and their own goals of what kind/type of knowledge they wish to extract and model with graphrag."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "## Build an Index\n",
    "\n",
    "After data files have been uploaded and (optionally) custom promps have been generated, it is time to construct a knowledge graph by building an index. If custom prompts are not provided (demonstrated in the `1-Quickstart` notebook), default built-in prompts are used that we find generally work well."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23",
   "metadata": {},
   "source": [
    "#### Start a new indexing job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    'status': 'Indexing job scheduled',\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# check if custom prompts were generated\n",
    "if \"auto_template_response\" in locals() and auto_template_response.ok:\n",
    "    entity_extraction_prompt = prompts[\"entity_extraction_prompt\"]\n",
    "    community_summarization_prompt = prompts[\"community_summarization_prompt\"]\n",
    "    summarize_description_prompt = prompts[\"entity_summarization_prompt\"]\n",
    "else:\n",
    "    entity_extraction_prompt = community_summarization_prompt = summarize_description_prompt = None\n",
    "\n",
    "response = build_index(\n",
    "    storage_name=storage_name,\n",
    "    index_name=index_name,\n",
    "    entity_extraction_prompt=entity_extraction_prompt,\n",
    "    community_summarization_prompt=community_summarization_prompt,\n",
    "    entity_summarization_prompt=summarize_description_prompt,\n",
    ")\n",
    "if response.ok:\n",
    "    pprint(response.json())\n",
    "else:\n",
    "    print(f\"Failed to submit job.\\nStatus: {response.text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {},
   "source": [
    "Note: indexing jobs are submitted to a queue to run. A cronjob checks every 5 minutes to schedule new jobs if possible.\n",
    "\n",
    "An indexing job can sometimes fail due to insufficient TPM quota of the Azure OpenAI model. In this situation, an indexing job can be restarted by re-running the cell above with the same parameters. `graphrag` caches previous indexing results as a cost-savings measure so that restarting indexing jobs will effectively \"pick up\" where they left off."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {},
   "source": [
    "#### Check index job status\n",
    "\n",
    "Please wait for the index to reach 100 percent completion before continuing on to the next section (running queries). You may rerun the next cell multiple times to monitor status. Note: the indexing speed of graphrag is directly correlated to the TPM quota of the Azure OpenAI model you are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "27",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [200]>\n",
      "{\n",
      "    'status_code': 200,\n",
      "    'index_name': 'indexAdvanced',\n",
      "    'storage_name': 'blob',\n",
      "    'status': 'complete',\n",
      "    'percent_complete': 100.0,\n",
      "    'progress': '11 out of 11 workflows completed successfully.',\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "response = index_status(index_name)\n",
    "print(response)\n",
    "if response.ok:\n",
    "    pprint(response.json())\n",
    "else:\n",
    "    print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28",
   "metadata": {},
   "source": [
    "#### List indexes\n",
    "To view a list of all indexes that exist in the GraphRAG service:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "    'indexdata',\n",
      "    'indexAdvanced',\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "all_indexes = list_indexes()\n",
    "pprint(all_indexes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30",
   "metadata": {},
   "source": [
    "#### Delete an indexing job\n",
    "If an index is no longer needed, remove it from the GraphRAG service."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # uncomment this cell to delete an index\n",
    "#response = delete_index(index_name)\n",
    "#print(response)\n",
    "#pprint(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "## Query\n",
    "\n",
    "Once an indexing job is complete, the knowledge graph is ready to query. Two types of queries (global and local) are currently supported. We encourage you to try both and experience the difference in responses. Note that query response time is also correlated to the TPM quota of the Azure OpenAI model you are using."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33",
   "metadata": {},
   "source": [
    "#### Global Search\n",
    "\n",
    "Global search queries are resource-intensive, but give good responses to questions that require an understanding of the dataset as a whole."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "34",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Overview of Returns and Refunds Process\n",
      "\n",
      "The returns and refunds process for physical products is a critical aspect of customer service that significantly impacts customer satisfaction and trust. This process is governed by several key entities and actions that ensure its effectiveness and transparency.\n",
      "\n",
      "### Key Entities and Their Roles\n",
      "\n",
      "1. **Returns**: This is the central entity in the returns and refunds community. It represents the process of returning products for a refund or exchange. The high connectivity of the Returns entity with other relevant entities underscores its pivotal role in the entire process [Data: Reports (3)].\n",
      "\n",
      "2. **Email**: Email acts as a vital communication channel through which customers can make inquiries and receive notifications related to returns and refunds. It facilitates the return process by allowing customers to initiate returns directly through email communication [Data: Reports (3)].\n",
      "\n",
      "3. **Request Return**: This action enables customers to start the process of returning a product. By using the Request Return function, customers can express their need to return a product, which is a crucial step in the return process [Data: Reports (3)].\n",
      "\n",
      "4. **Refund Timeline**: This entity provides information on when refunds will be issued following a return. It plays a crucial role in setting and managing customer expectations regarding the timing of their refunds, thereby enhancing transparency in the process [Data: Reports (3)].\n",
      "\n",
      "5. **Return Policy**: The Return Policy sets the guidelines and rules that customers and businesses must follow during the returns process. It ensures that returns are handled consistently and fairly, which helps in building customer trust and satisfaction [Data: Reports (3)].\n",
      "\n",
      "### Implications for Customer Satisfaction\n",
      "\n",
      "The interconnectedness of these entities ensures that the returns and refunds process is smooth and customer-friendly. The central role of Returns, supported by direct communication through Email and clear guidelines provided by the Return Policy, facilitates a seamless experience. Moreover, the clarity provided by the Refund Timeline helps manage expectations effectively, which is crucial for maintaining customer satisfaction.\n",
      "\n",
      "In conclusion, understanding these key components and their roles can help businesses optimize their returns and refunds processes, ultimately leading to higher customer satisfaction and loyalty.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'reports': [{'id': '3',\n",
       "   'title': 'Returns and Refunds Community',\n",
       "   'occurrence weight': 1.0,\n",
       "   'content': '# Returns and Refunds Community\\n\\nThe community revolves around the process of Returns and Refunds, with key entities including Returns, Email, Request Return, Refund Timeline, and Return Policy. These entities are interconnected through relationships that govern the return and refund process.\\n\\n## Returns as the central entity\\n\\nReturns is the central entity in this community, representing the process of returning products for a refund or exchange. It has the highest degree among all entities, indicating its critical role in the community. The relationships of Returns with Email, Request Return, Refund Timeline, and Return Policy highlight its importance in governing the return process and ensuring customer satisfaction. [Data: Entities (2, 4, 12, 14, 15); Relationships (2, 4, 5, 0)]\\n\\n## Email as a communication channel\\n\\nEmail serves as a communication channel for customer inquiries and notifications related to returns and refunds. Its degree indicates a moderate level of importance within the community. The relationship between Returns and Email suggests that customers can request returns via email, emphasizing the role of Email in facilitating the return process. [Data: Entities (12); Relationships (2)]\\n\\n## Request Return action\\n\\nRequest Return is an action that allows customers to initiate product returns. While it has a lower degree compared to Returns and Email, its relationship with Returns underscores its significance in the return process. Customers can use the Request Return action to request returns, indicating its role in facilitating customer interactions. [Data: Entities (14); Relationships (4)]\\n\\n## Refund Timeline for issuing refunds\\n\\nRefund Timeline specifies when refunds are issued after returns, providing clarity and transparency to customers. Its relationship with Returns highlights the connection between returns and refunds, ensuring that refunds are issued in a timely manner according to the specified timeline. The Refund Timeline plays a crucial role in managing customer expectations and satisfaction. [Data: Entities (15); Relationships (5)]\\n\\n## Role of Return Policy\\n\\nReturn Policy governs the returns process, setting guidelines and rules for customers and businesses to follow. While it has the lowest degree among entities, its relationship with Returns indicates its importance in defining the terms and conditions of returns. The Return Policy ensures consistency and fairness in handling returns, contributing to customer trust and satisfaction. [Data: Entities (11); Relationships (0)]',\n",
       "   'rank': 7.5},\n",
       "  {'id': '1',\n",
       "   'title': 'Payment and Subscription Management Community',\n",
       "   'occurrence weight': 1.0,\n",
       "   'content': '# Payment and Subscription Management Community\\n\\nThe community revolves around payment and subscription management, with key entities such as Payments, Subscriptions, Payment Policy, Subscription Policy, Update Payment Info, and Cancel Subscription. These entities are interconnected through relationships governing payment methods, refund processes, subscription terms, and actions for updating or canceling subscriptions.\\n\\n## Payments and Payment Policy relationship\\n\\nPayments are governed by the Payment Policy, which outlines accepted payment methods and refund processes. This relationship ensures that payment transactions adhere to the established guidelines, providing clarity and consistency for customers and businesses [Data: Relationships (20)].\\n\\n## Subscriptions and Subscription Policy governance\\n\\nSubscriptions are governed by the Subscription Policy, which dictates renewal and cancellation terms. This governance framework ensures that subscription services operate within defined parameters, offering transparency and predictability for subscribers and service providers [Data: Relationships (26)].\\n\\n## Update Payment Info action\\n\\nThe Update Payment Info action allows users to modify their payment details, enabling them to manage their payment information conveniently. This action enhances user control and flexibility in maintaining accurate and up-to-date payment information, contributing to a positive user experience [Data: Entities (21), Relationships (21)].\\n\\n## Cancel Subscription action\\n\\nThe Cancel Subscription action enables users to terminate recurring subscriptions, providing them with an option to discontinue subscription services. This action empowers users with control over their subscription commitments, aligning with principles of customer choice and service flexibility [Data: Entities (23), Relationships (27)].\\n\\n## Live Chat as a support channel\\n\\nLive Chat serves as a real-time support channel for customer assistance, offering immediate help and guidance to users. This support channel enhances customer service capabilities, enabling prompt resolution of queries and issues, which can positively impact customer satisfaction and loyalty [Data: Entities (13), Relationships (3)].',\n",
       "   'rank': 7.5},\n",
       "  {'id': '2',\n",
       "   'title': 'Shipping and Delivery Community',\n",
       "   'occurrence weight': 1.0,\n",
       "   'content': '# Shipping and Delivery Community\\n\\nThe community revolves around the processes of Shipping, Delivery, and Orders, with Shipping being available in specified Shipping Zones. Shipping is related to Delivery and Delivery Guarantee, while Orders can be tracked using the Track Order action.\\n\\n## Shipping as the core process\\n\\nShipping is the central process in this community, involving sending products to customers within specified zones and timeframes. The availability of Shipping in specified Shipping Zones is crucial for reaching customers effectively. The relationship between Shipping and Delivery, as well as Delivery Guarantee, highlights the importance of timely and efficient shipping processes in this community. [Data: Entities (3, 16), Relationships (6, 7, 10)]\\n\\n## Delivery process and guarantee\\n\\nDelivery is a key aspect of this community, ensuring that orders are delivered to customers within specified timeframes. The presence of a Delivery Guarantee further emphasizes the commitment to timely delivery. The relationship between Shipping and Delivery, as well as Delivery Guarantee, underscores the interconnectedness of these processes in fulfilling customer orders efficiently. [Data: Entities (8, 26), Relationships (7, 10)]\\n\\n## Importance of tracking orders\\n\\nOrders play a crucial role in this community, representing customer requests for products that need to be tracked and shipped. The ability to track orders using the Track Order action enhances customer experience and ensures transparency in the delivery process. The relationship between Orders and Track Order highlights the importance of order tracking in maintaining customer satisfaction. [Data: Entities (5, 17), Relationships (15)]',\n",
       "   'rank': 7.5},\n",
       "  {'id': '0',\n",
       "   'title': 'Account Security and Policy',\n",
       "   'occurrence weight': 1.0,\n",
       "   'content': \"# Account Security and Policy\\n\\nThe community revolves around account security and policy, where users' personal information and settings (Account) are protected by security measures and governed by an Account Policy. Users can Reset Passwords as an action within this community, and security inquiries can be made via Phone. Reporting Fraud is a security measure to protect against fraudulent activities.\\n\\n## Account Security as a Priority\\n\\nAccount Security is a key focus in this community, with security measures in place to protect accounts and prevent fraud. The relationship between Security and Reporting Fraud highlights the importance of proactive measures to safeguard user information and prevent unauthorized access. The degree of Account (4) indicates the critical nature of securing user data within this community. [Data: Entities (9, 24); Relationships (24)]\\n\\n## Account Policy Enforcement\\n\\nThe Account Policy governs user actions within this community, requiring users to register with valid email and maintain security. The relationship between Account and Account Policy emphasizes the importance of adhering to established guidelines to ensure the integrity of user accounts. The combined degree of Account and Account Policy (5) underscores the significance of policy enforcement in maintaining a secure environment. [Data: Entities (19); Relationships (17)]\\n\\n## Reset Password Functionality\\n\\nThe ability for users to Reset Passwords is a critical feature within this community, allowing users to update their account credentials for enhanced security. The relationship between Account and Reset Password highlights the user-centric approach to account management, providing users with the necessary tools to maintain account security. The combined degree of Account and Reset Password (5) indicates the importance of this functionality in the community. [Data: Entities (18); Relationships (16)]\\n\\n## Role of Phone in Security Inquiries\\n\\nPhone serves as a communication channel for customer support and security inquiries within this community. The relationship between Security and Phone suggests that users can seek assistance and address security concerns through direct communication. The combined degree of Security and Phone (4) underscores the significance of providing users with accessible channels for security-related inquiries. [Data: Entities (25); Relationships (25)]\",\n",
       "   'rank': 7.5}],\n",
       " 'entities': [],\n",
       " 'relationships': [],\n",
       " 'claims': [],\n",
       " 'sources': []}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in a single index name as a string or to query across multiple indexes, set index_name=[myindex1, myindex2]\n",
    "global_response = global_search(\n",
    "    index_name=index_name,\n",
    "    query=\"How do returns and refunds work for physical products?\",\n",
    "    community_level=1,\n",
    ")\n",
    "# print the result and save context data in a variable\n",
    "global_response_data = parse_query_response(global_response, return_context_data=True)\n",
    "global_response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37",
   "metadata": {},
   "source": [
    "#### Local Search\n",
    "\n",
    "Local search queries are best suited for narrow-focused questions that require an understanding of specific entities mentioned in the documents (e.g. What are the healing properties of chamomile?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "38",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Server Error\n",
      "b'Internal Server Error'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Response [500]>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# pass in a single index name as a string or to query across multiple indexes, set index_name=[myindex1, myindex2]\n",
    "local_response = local_search(\n",
    "    index_name=index_name,\n",
    "    query=\"Can I contact support via email?\",\n",
    "    community_level=2,\n",
    ")\n",
    "# print the result and save context data in a variable\n",
    "local_response_data = parse_query_response(local_response, return_context_data=True)\n",
    "local_response_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "In a query response, citations will often appear that support GraphRAG's response. API endpoints are provided to enable retrieval of the sourced documents, entities, relationships, etc.\n",
    "\n",
    "Multiple types of sources may be referenced in a query: Reports, Entities, Relationships, Claims, and Text Units. The API provides various endpoints to retrieve these sources for data provenance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42",
   "metadata": {},
   "source": [
    "#### Get a Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "43",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"title\": \"Account Security and Policy\",\n",
      "    \"summary\": \"The community revolves around account security and policy, where users' personal information and settings (Account) are protected by security measures and governed by an Account Policy. Users can Reset Passwords as an action within this community, and security inquiries can be made via Phone. Reporting Fraud is a security measure to protect against fraudulent activities.\",\n",
      "    \"findings\": [\n",
      "        {\n",
      "            \"summary\": \"Account Security as a Priority\",\n",
      "            \"explanation\": \"Account Security is a key focus in this community, with security measures in place to protect accounts and prevent fraud. The relationship between Security and Reporting Fraud highlights the importance of proactive measures to safeguard user information and prevent unauthorized access. The degree of Account (4) indicates the critical nature of securing user data within this community. [Data: Entities (9, 24); Relationships (24)]\"\n",
      "        },\n",
      "        {\n",
      "            \"summary\": \"Account Policy Enforcement\",\n",
      "            \"explanation\": \"The Account Policy governs user actions within this community, requiring users to register with valid email and maintain security. The relationship between Account and Account Policy emphasizes the importance of adhering to established guidelines to ensure the integrity of user accounts. The combined degree of Account and Account Policy (5) underscores the significance of policy enforcement in maintaining a secure environment. [Data: Entities (19); Relationships (17)]\"\n",
      "        },\n",
      "        {\n",
      "            \"summary\": \"Reset Password Functionality\",\n",
      "            \"explanation\": \"The ability for users to Reset Passwords is a critical feature within this community, allowing users to update their account credentials for enhanced security. The relationship between Account and Reset Password highlights the user-centric approach to account management, providing users with the necessary tools to maintain account security. The combined degree of Account and Reset Password (5) indicates the importance of this functionality in the community. [Data: Entities (18); Relationships (16)]\"\n",
      "        },\n",
      "        {\n",
      "            \"summary\": \"Role of Phone in Security Inquiries\",\n",
      "            \"explanation\": \"Phone serves as a communication channel for customer support and security inquiries within this community. The relationship between Security and Phone suggests that users can seek assistance and address security concerns through direct communication. The combined degree of Security and Phone (4) underscores the significance of providing users with accessible channels for security-related inquiries. [Data: Entities (25); Relationships (25)]\"\n",
      "        }\n",
      "    ],\n",
      "    \"rating\": 7.5,\n",
      "    \"rating_explanation\": \"The impact severity rating is high due to the critical nature of account security and the potential risks associated with fraudulent activities.\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "report_response = get_report(index_name, 0)\n",
    "print(report_response.json()[\"text\"]) if report_response.ok else (\n",
    "    report_response.reason,\n",
    "    report_response.content,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44",
   "metadata": {},
   "source": [
    "#### Get an Entity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "45",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'PHYSICAL PRODUCT',\n",
       " 'description': 'Physical Product is a tangible item that can be returned or shipped',\n",
       " 'text_units': ['fd8484d12602ea36a091e64d6291df06c69c3cceb19957983a50ba8f2f2f11ba34c9dd644bf133b53272b161c32b52070a00415fbfa807a270fa9c274d507bce']}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_response = get_entity(index_name, 0)\n",
    "entity_response.json() if entity_response.ok else (\n",
    "    entity_response.reason,\n",
    "    entity_response.content,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get a Relationship"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "47",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': 'RETURNS',\n",
       " 'source_id': 2,\n",
       " 'target': 'REFUNDS',\n",
       " 'target_id': 4,\n",
       " 'description': 'Returns are related to Refunds',\n",
       " 'text_units': ['fd8484d12602ea36a091e64d6291df06c69c3cceb19957983a50ba8f2f2f11ba34c9dd644bf133b53272b161c32b52070a00415fbfa807a270fa9c274d507bce']}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_response = get_relationship(index_name, 1)\n",
    "relationship_response.json() if relationship_response.ok else (\n",
    "    relationship_response.reason,\n",
    "    relationship_response.content,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48",
   "metadata": {},
   "source": [
    "#### Get a Claim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<Response [500]>\n",
      "{\"detail\":\"Claim data unavailable for index 'indexAdvanced'.\"}\n"
     ]
    }
   ],
   "source": [
    "claim_response = get_claim(index_name, 1)\n",
    "if claim_response.ok:\n",
    "    pprint(claim_response.json())\n",
    "else:\n",
    "    print(claim_response)\n",
    "    print(claim_response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50",
   "metadata": {
    "tags": []
   },
   "source": [
    "#### Get a Text Unit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Internal Server Error\n",
      "b'Internal Server Error'\n"
     ]
    }
   ],
   "source": [
    "# get a text unit id from one of the previous Source endpoint results (look for 'text_units' in the response)\n",
    "text_unit_id = \"\"\n",
    "if not text_unit_id:\n",
    "    raise ValueError(\n",
    "        \"Must provide a text_unit_id from previous source results. Look for 'text_units' in the response.\"\n",
    "    )\n",
    "text_unit_response = get_text_unit(index_name, text_unit_id)\n",
    "if text_unit_response.ok:\n",
    "    print(text_unit_response.json()[\"text\"])\n",
    "else:\n",
    "    print(text_unit_response.reason)\n",
    "    print(text_unit_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52",
   "metadata": {},
   "source": [
    "## Exploring the GraphRAG knowledge graph\n",
    "To better understand the knowledge graph that was constructed during the indexing process, the API provides an option to download a graphml file, which can be imported by other open source visualization software (we recommend [Gephi](https://gephi.org/)) for deeper exploration."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53",
   "metadata": {},
   "source": [
    "#### Get a GraphML file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# will save graphml file to the current local directory\n",
    "save_graphml_file(index_name, \"knowledge_graph.graphml\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
